<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Publications - Heehyeon Kim">
    <title>Publications - Heehyeon</title>
    <link rel="stylesheet" href="css/style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <nav class="navbar">
        <div class="nav-container">
            <a href="index.html" class="logo">~/heehyeon</a>
            <ul class="nav-menu">
                <li><a href="index.html#about" class="nav-link">Home</a></li>
                <li><a href="publications.html" class="nav-link active">Publications</a></li>
                <li><a href="index.html#cv" class="nav-link">CV</a></li>
            </ul>
            <button class="menu-toggle" aria-label="Toggle menu">
                <span></span>
                <span></span>
                <span></span>
            </button>
        </div>
    </nav>

    <main>
        <!-- Publications Section -->
        <section id="publications" class="section">
            <div class="container">
                <div class="publications-page-header">
                    <a href="index.html" class="back-link">← Back to Home</a>
                    <h1 class="page-title">Publications</h1>
                    <p class="page-subtitle">A comprehensive list of my research publications</p>
                </div>
                <div class="publications-list">
                    <div class="publication-item">
                        <div class="pub-year">2025</div>
                        <div class="pub-content">
                            <h3 class="pub-title">Beneath the Facade: Probing Safety Vulnerabilities in LLMs via Auto-Generated Jailbreak Prompts</h3>
                            <p class="pub-authors">H. Kim, K. Lee, and J. J. Whang*</p>
                            <p class="pub-venue">Findings of the Association for Computational Linguistics: EMNLP (Findings of EMNLP), 2025.</p>
                            <div class="pub-links">
                                <a href="https://aclanthology.org/2025.findings-emnlp.960/" class="pub-link">Paper</a>
                                <a href="https://github.com/bdi-lab/TroGEN" class="pub-link">Code</a>
                                <a href="assets/slides/emnlp2025-slides.pdf" class="pub-link" target="_blank">Slides</a>
                                <a href="assets/poster/emnlp2025-poster.pdf" class="pub-link" target="_blank">Poster</a>
                            </div>
                            <button class="pub-abstract-toggle" data-abstract-id="pub-abstract-1">View abstract</button>
                            <div class="pub-abstract" id="pub-abstract-1">
                                <p>The rapid proliferation of large language models and multimodal generative models has raised concerns about their potential vulnerabilities to a wide range of real-world safety risks. However, a critical gap persists in systematic assessment, alongside the lack of evaluation frameworks to keep pace with the breadth and variability of real-world risk factors. In this paper, we introduce TroGEN, an automated jailbreak prompt generation framework that assesses these vulnerabilities by deriving scenario-driven jailbreak prompts using an adversarial agent. Moving beyond labor-intensive dataset construction, TroGEN features an extensible design that covers broad range of risks, supports plug-and-play jailbreak strategies, and adapts seamlessly to multimodal settings. Experimental results demonstrate that TroGEN effectively uncovers safety weaknesses, revealing susceptibilities to adversarial attacks that conceal malicious intent beneath an apparently benign facade, like a Trojan horse. Furthermore, such stealthy attacks exhibit resilience even against existing jailbreak defense methods.</p>
                            </div>
                        </div>
                    </div>
                    <div class="publication-item">
                        <div class="pub-year">2025</div>
                        <div class="pub-content">
                            <h3 class="pub-title">Unveiling the Threat of Fraud Gangs to Graph Neural Networks: Multi-Target Graph Injection Attacks against GNN-Based Fraud Detectors</h3>
                            <p class="pub-authors">J. Choi, H. Kim, and J. J. Whang*</p>
                            <p class="pub-venue">AAAI Conference on Artificial Intelligence (AAAI), 2025.</p>
                            <div class="pub-links">
                                <a href="https://ojs.aaai.org/index.php/AAAI/article/view/33760" class="pub-link">Paper</a>
                                <a href="https://github.com/bdi-lab/MonTi" class="pub-link">Code</a>
                                <a href="assets/slides/aaai2025-slides.pdf" class="pub-link" target="_blank">Slides</a>
                                <a href="assets/poster/aaai2025-poster.pdf" class="pub-link" target="_blank">Poster</a>
                            </div>
                            <button class="pub-abstract-toggle" data-abstract-id="pub-abstract-2">View abstract</button>
                            <div class="pub-abstract" id="pub-abstract-2">
                                <p>Graph neural networks (GNNs) have emerged as an effective tool for fraud detection, identifying fraudulent users, and uncovering malicious behaviors. However, attacks against GNN-based fraud detectors and their risks have rarely been studied, thereby leaving potential threats unaddressed. Recent findings suggest that frauds are increasingly organized as gangs or groups. In this work, we design attack scenarios where fraud gangs aim to make their fraud nodes misclassified as benign by camouflaging their illicit activities in collusion. Based on these scenarios, we study adversarial attacks against GNN-based fraud detectors by simulating attacks of fraud gangs in three real-world fraud cases: spam reviews, fake news, and medical insurance frauds. We define these attacks as multi-target graph injection attacks and propose MonTi, a transformer-based Multi-target one-Time graph injection attack model. MonTi simultaneously generates attributes and edges of all attack nodes with a transformer encoder, capturing interdependencies between attributes and edges more effectively than most existing graph injection attack methods that generate these elements sequentially. Additionally, MonTi adaptively allocates the degree budget for each attack node to explore diverse injection structures involving target, candidate, and attack nodes, unlike existing methods that fix the degree budget across all attack nodes. Experiments show that MonTi outperforms the state-of-the-art graph injection attack methods on five real-world graphs.</p>
                            </div>
                        </div>
                    </div>
                    <div class="publication-item">
                        <div class="pub-year">2025</div>
                        <div class="pub-content">
                            <h3 class="pub-title">SAIF: A Comprehensive Framework for Evaluating the Risks of Generative AI in the Public Sector</h3>
                            <p class="pub-authors">K. Lee, H. Kim, and J. J. Whang*</p>
                            <p class="pub-venue">AI for Public Missions (AIPM) Workshop at AAAI Conference on Artificial Intelligence (AAAI), 2025.</p>
                            <div class="pub-links">
                                <a href="https://arxiv.org/abs/2501.08814" class="pub-link">Paper</a>
                                <a href="assets/slides/aipm2025-slides.pdf" class="pub-link" target="_blank">Slides</a>
                                <a href="assets/poster/aipm2025-poster.pdf" class="pub-link" target="_blank">Poster</a>
                            </div>
                            <button class="pub-abstract-toggle" data-abstract-id="pub-abstract-3">View abstract</button>
                            <div class="pub-abstract" id="pub-abstract-3">
                                <p>The rapid adoption of generative AI in the public sector, encompassing diverse applications ranging from automated public assistance to welfare services and immigration processes, highlights its transformative potential while underscoring the pressing need for thorough risk assessments. Despite its growing presence, evaluations of risks associated with AI-driven systems in the public sector remain insufficiently explored. Building upon an established taxonomy of AI risks derived from diverse government policies and corporate guidelines, we investigate the critical risks posed by generative AI in the public sector while extending the scope to account for its multimodal capabilities. In addition, we propose a Systematic dAta generatIon Framework for evaluating the risks of generative AI (SAIF). SAIF involves four key stages: breaking down risks, designing scenarios, applying jailbreak methods, and exploring prompt types. It ensures the systematic and consistent generation of prompt data, facilitating a comprehensive evaluation while providing a solid foundation for mitigating the risks. Furthermore, SAIF is designed to accommodate emerging jailbreak methods and evolving prompt types, thereby enabling effective responses to unforeseen risk scenarios. We believe that this study can play a crucial role in fostering the safe and responsible integration of generative AI into the public sector.</p>
                            </div>
                        </div>
                    </div>
                    <div class="publication-item">
                        <div class="pub-year">2024</div>
                        <div class="pub-content">
                            <h3 class="pub-title">SpoT-Mamba: Learning Long-Range Dependency on Spatio-Temporal Graphs with Selective State Spaces</h3>
                            <p class="pub-authors">J. Choi, H. Kim, M. An, and J. J. Whang*</p>
                            <p class="pub-venue">Spatio-Temporal Reasoning and Learning (STRL) Workshop at International Joint Conference on Artificial Intelligence (IJCAI), 2024.</p>
                            <div class="pub-links">
                                <a href="https://ceur-ws.org/Vol-3827/" class="pub-link">Paper</a>
                                <a href="https://github.com/bdi-lab/SpoT-Mamba" class="pub-link">Code</a>
                                <a href="assets/slides/strl2024-slides.pdf" class="pub-link" target="_blank">Slides</a>
                            </div>
                            <button class="pub-abstract-toggle" data-abstract-id="pub-abstract-4">View abstract</button>
                            <div class="pub-abstract" id="pub-abstract-4">
                                <p>Spatio-temporal graph (STG) forecasting is a critical task with extensive applications in the real world, including traffic and weather forecasting. Although several recent methods have been proposed to model complex dynamics in STGs, addressing long-range spatio-temporal dependencies remains a significant challenge, leading to limited performance gains. Inspired by a recently proposed state space model named Mamba, which has shown remarkable capability of capturing long-range dependency, we propose a new STG forecasting framework named SpoT-Mamba. SpoT-Mamba generates node embeddings by scanning various node-specific walk sequences. Based on the node embeddings, it conducts temporal scans to capture long-range spatio-temporal dependencies. Experimental results on the real-world traffic forecasting dataset demonstrate the effectiveness of SpoT-Mamba.</p>
                            </div>
                        </div>
                    </div>
                    <div class="publication-item">
                        <div class="pub-year">2023</div>
                        <div class="pub-content">
                            <h3 class="pub-title">Dynamic Relation-Attentive Graph Neural Networks for Fraud Detection</h3>
                            <p class="pub-authors">H. Kim, J. Choi, and J. J. Whang*</p>
                            <p class="pub-venue">Machine Learning on Graphs (MLoG) Workshop at IEEE International Conference on Data Mining (ICDM), 2023.</p>
                            <div class="pub-links">
                                <a href="https://ieeexplore.ieee.org/document/10411688" class="pub-link">Paper</a>
                                <a href="https://github.com/bdi-lab/DRAG" class="pub-link">Code</a>
                                <a href="assets/poster/icdm2023-poster.pdf" class="pub-link" target="_blank">Poster</a>
                            </div>
                            <button class="pub-abstract-toggle" data-abstract-id="pub-abstract-5">View abstract</button>
                            <div class="pub-abstract" id="pub-abstract-5">
                                <p>Fraud detection aims to discover fraudsters deceiving other users by, for example, leaving fake reviews or making abnormal transactions. Graph-based fraud detection methods consider this task as a classification problem with two classes: frauds or normal. We address this problem using Graph Neural Networks (GNNs) by proposing a dynamic relation-attentive aggregation mechanism. Based on the observation that many real-world graphs include different types of relations, we propose to learn a node representation per relation and aggregate the node representations using a learnable attention function that assigns a different attention coefficient to each relation. Furthermore, we combine the node representations from different layers to consider both the local and global structures of a target node, which is beneficial to improving the performance of fraud detection on graphs with heterophily. By employing dynamic graph attention in all the aggregation processes, our method adaptively computes the attention coefficients for each node. Experimental results show that our method, DRAG, outperforms state-of-the-art fraud detection methods on real-world benchmark datasets.</p>
                            </div>
                        </div>
                    </div>
                    <div class="publication-item">
                        <div class="pub-year">2022</div>
                        <div class="pub-content">
                            <h3 class="pub-title">HAZE-Net: High-Frequency Attentive Super-Resolved Gaze Estimation in Low-Resolution Face Images</h3>
                            <p class="pub-authors">JS. Yun, Y. Na, H. Kim, HI Kim, SB. Yoo*</p>
                            <p class="pub-venue">Asian Conference on Computer Vision (ACCV), 2022.</p>
                            <div class="pub-links">
                                <a href="#" class="pub-link">Paper</a>
                                <a href="#" class="pub-link">Code</a>
                            </div>
                            <button class="pub-abstract-toggle" data-abstract-id="pub-abstract-6">View abstract</button>
                            <div class="pub-abstract" id="pub-abstract-6">
                                <p>Although gaze estimation methods have been developed with deep learning techniques, there has been no such approach as aim to attain accurate performance in low-resolution face images with a pixel width of 50 pixels or less. To solve a limitation under the challenging low-resolution conditions, we propose a high-frequency attentive superresolved gaze estimation network, i.e., HAZE-Net. Our network improves the resolution of the input image and enhances the eye features and those boundaries via a proposed super-resolution module based on a high-frequency attention block. In addition, our gaze estimation module utilizes high-frequency components of the eye as well as the global appearance map. We also utilize the structural location information of faces to approximate head pose. The experimental results indicate that the proposed method exhibits robust gaze estimation performance even in low-resolution face images with 28×28 pixels. The source code of this work is available at https://github.com/dbseorms16/HAZE_Net/.</p>
                            </div>
                        </div>
                    </div>
                    <div class="publication-item">
                        <div class="pub-year">2022</div>
                        <div class="pub-content">
                            <h3 class="pub-title">LatentGaze: Cross-Domain Gaze Estimation through Gaze-Aware Analytic Latent Code Manipulation</h3>
                            <p class="pub-authors">I. Lee, JS. Yun, H. Kim, Y. Na, SB. Yoo*</p>
                            <p class="pub-venue">Asian Conference on Computer Vision (ACCV), 2022.</p>
                            <div class="pub-links">
                                <a href="#" class="pub-link">Paper</a>
                                <a href="#" class="pub-link">Code</a>
                            </div>
                            <button class="pub-abstract-toggle" data-abstract-id="pub-abstract-7">View abstract</button>
                            <div class="pub-abstract" id="pub-abstract-7">
                                <p>Although recent gaze estimation methods lay great emphasis on attentively extracting gaze-relevant features from facial or eyeimages, how to define features that include gaze-relevant components has been ambiguous. This obscurity makes the model learn not only gaze-relevant features but also irrelevant ones. In particular, it is fatal for the cross-dataset performance. To overcome this challenging issue, we propose a gaze-aware analytic manipulation method, based on a data-driven approach with generative adversarial network inversion’s disentanglement characteristics, to selectively utilize gaze-relevant features in a latent code. Furthermore, by utilizing GANbased encoder-generator process, we shift the input image from the target domain to the source domain image, which a gaze estimator is sufficiently aware. In addition, we propose gaze distortion loss in the encoder that prevents the distortion of gaze information. The experimental results demonstrate that our method achieves state-of-the-art gaze estimation accuracy in a cross-domain gaze estimation tasks. This code is available at https://github.com/leeisack/LatentGaze/.</p>
                            </div>
                        </div>
                    </div>
                    <div class="publication-item">
                        <div class="pub-year">2022</div>
                        <div class="pub-content">
                            <h3 class="pub-title">Shared Knowledge Distillation for Robust Multi-Scale Super-Resolution Networks</h3>
                            <p class="pub-authors">Y. Na, H. Kim, and SB. Yoo*</p>
                            <p class="pub-venue">IET Electronics Letters, 2022.</p>
                            <div class="pub-links">
                                <a href="https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/ell2.12526" class="pub-link">Paper</a>
                            </div>
                            <button class="pub-abstract-toggle" data-abstract-id="pub-abstract-8">View abstract</button>
                            <div class="pub-abstract" id="pub-abstract-8">
                                <p>Although developments in deep learning have resulted in considerable perormance enhancements in super-resolution (SR), they have also caused substantial increases in computational costs and memory requirements. Thus, various compression techniques, such as quantisation, pruning, and knowledge distillation (KD), for single SR models have been introduced. However, multiple SR models are required in the real world to robustly reconstruct low-resolution (LR) images of varying input sizes. Because of the limited resources, storing multiple models is impossible for mobile devices and embedded systems. In this letter, we propose a multi-scale SR network using weight-sharing method to effectively eliminate redundant parameters. To train our multi-scale SR network and mitigate SR performance degradation due to knowledge confusion, we divide backpropagation into two stages. Furthermore, we propose a compression framework that distils shared knowledge within a multi-scale SR network. We achieve a compression rate of 94% from storing multiple scales of single SR models, while only compromising 0.3 dB on average in terms of peak signal-to-noise ratio (PSNR).</p>
                            </div>
                        </div>
                    </div>
                    <!-- Add more publications here as needed -->
                </div>
            </div>
        </section>
    </main>

    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <p>&copy; 2026 Heehyeon. All rights reserved.</p>
                <div class="social-links">
                    <a href="https://github.com/h22hyeon" target="_blank" rel="noopener noreferrer" class="social-link">GitHub</a>
                    <a href="https://twitter.com" target="_blank" rel="noopener noreferrer" class="social-link">Twitter</a>
                    <a href="mailto:your.email@example.com" class="social-link">Email</a>
                </div>
            </div>
        </div>
    </footer>

    <script src="js/main.js"></script>
</body>
</html>

